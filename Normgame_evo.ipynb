{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm Game with Tool of punishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "import os, random\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0.7)\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, name, trait, game_direction):\n",
    "        self.name = name\n",
    "        self.trait = trait\n",
    "        self.score = 0\n",
    "        self.cheated = False\n",
    "        self.game_direction = game_direction\n",
    "        self.memory = []\n",
    "        # プロンプトのテンプレート\n",
    "        self.prompt = \"\"\n",
    "\n",
    "    def get_prompt(self):\n",
    "        self.prompt = f\"\"\"\n",
    "        You are a player in this game, fully immersed in your role.\n",
    "        Your goal is to win the game by accumulating the most points.\n",
    "        You can earn points by making strategic decisions and interacting with other players.\n",
    "\n",
    "        Name: {self.name}\n",
    "\n",
    "        Character Traits:\n",
    "        {self.trait}\n",
    "\n",
    "        Game Instructions:\n",
    "        {self.game_direction}\n",
    "\n",
    "        Discussion Log:\n",
    "        {self.memory}\n",
    "\n",
    "        Remember, your actions in the game should align with your character's traits. Let these guide your decisions and interactions.\n",
    "        \"\"\"\n",
    "        return self.prompt\n",
    "\n",
    "    def add_memory(self, item, memory_size=30):\n",
    "        if len(self.memory) >= memory_size:\n",
    "            self.memory.pop(0)\n",
    "        self.memory.append(item)\n",
    "\n",
    "def read_and_display_row(csv_path, index):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # ランダムな行を選択\n",
    "    row = df.iloc[index]\n",
    "\n",
    "    return row['Personality Traits']\n",
    "\n",
    "def generate_agents_with_random_character(personalities, n_agents, game_direction, csv_path):\n",
    "    Agent_names = [\"John\", \"Merry\", \"Steve\", \"Bob\", \"Alice\", \"Eve\", \"Carol\", \"David\", \"Frank\", \"Grace\", \"Heidi\", \"Ivy\", \"Jack\", \"Karl\", \"Liam\", \"Mia\", \"Noah\", \"Olga\", \"Paul\", \"Quin\", \"Rose\", \"Sean\", \"Tina\", \"Ulla\", \"Vera\", \"Wade\", \"Xena\", \"Yara\", \"Zane\"]\n",
    "    random.shuffle(Agent_names)\n",
    "    agents = []\n",
    "\n",
    "    for i in range(n_agents):\n",
    "        name = Agent_names[i]\n",
    "        trait = personalities[i] #read_and_display_row(csv_path, random_indices[i])\n",
    "        agents.append(Agent(name, trait, game_direction))\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全てのエージェントがテストを受けるフェーズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def get_score_by_TakeTest():\n",
    "    mean =50\n",
    "    variance = 10\n",
    "    min_val = 1\n",
    "    max_val =100\n",
    "\n",
    "    score = int(np.random.normal(mean, np.sqrt(variance)))\n",
    "    score = max(min(score, max_val), min_val)  # Ensure score is within bounds\n",
    "    return score\n",
    "\n",
    "def get_score_by_Cheat():\n",
    "    mean = 80\n",
    "    variance = 10\n",
    "    min_val = 1\n",
    "    max_val =100\n",
    "\n",
    "    score = int(np.random.normal(mean, np.sqrt(variance)))\n",
    "    score = max(min(score, max_val), min_val)  # Ensure score is within bounds\n",
    "    return score\n",
    "\n",
    "def extract_command(answer, agent):\n",
    "    taketest_match = re.search(r'<TakeTest>(.*?)</TakeTest>', answer)\n",
    "    cheat_match = re.search(r'<Cheat>(.*?)</Cheat>', answer)\n",
    "    if taketest_match:\n",
    "        score = get_score_by_TakeTest()\n",
    "    elif cheat_match:\n",
    "        score = get_score_by_Cheat()\n",
    "        agent.cheated = True\n",
    "    else:\n",
    "        score = 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_agents_take_test(agents):\n",
    "\n",
    "    take_test_prompt = \"\"\"\n",
    "    Your goal is to take high score in the game.\n",
    "    You can dicide whether cheat to get a score or not.\n",
    "    Please write your thought process. Give me your test score. Do your best!\n",
    "\n",
    "    If you want to take a test, command <TakeTest></TakeTest>\n",
    "    If you want to take a test with cheating and get a good score, command <Cheat></Cheat>\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(agents)):\n",
    "        agents[i].game_direction = take_test_prompt\n",
    "        answer = gpt4.predict(agents[i].get_prompt())\n",
    "\n",
    "        # スコアの抽出\n",
    "        score = extract_command(answer, agents[i])\n",
    "        agents[i].score = score\n",
    "\n",
    "        # メモリに追加\n",
    "        agents[i].add_memory(agents[i].game_direction)\n",
    "        agents[i].add_memory(answer)\n",
    "        agents[i].add_memory(f\"Your Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Makeing Score Annowncement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_announcement(agents):\n",
    "    score_announcement = \"The test scores are as follows: \\n\"\n",
    "    for i in range(len(agents)):\n",
    "        score_announcement += f\"{agents[i].name}: {agents[i].score}\"\n",
    "        if agents[i].cheated:\n",
    "            score_announcement += \"    [CHEATED]\"\n",
    "        score_announcement += \"\\n\"\n",
    "    print(score_announcement)\n",
    "\n",
    "    # メモリに追加\n",
    "    for i in range(len(agents)):\n",
    "        agents[i].add_memory(score_announcement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### メモリ覗き窓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_all_memory(agents):\n",
    "    for i in range(len):\n",
    "        for message in agents[i].memory:\n",
    "            print(f\"{agents[i].name}'s memmory : {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディスカッションを開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_agent_name(agents):\n",
    "    selected_agent = random.choice(agents)  # agentsリストからランダムにエージェントを選択します。\n",
    "    return selected_agent.name\n",
    "\n",
    "def get_agent_index_from_name(name, agents):\n",
    "    for index, agent in enumerate(agents):\n",
    "        if agent.name == name:\n",
    "            return index  # 名前が一致するエージェントの添え字を返します。\n",
    "    return None\n",
    "\n",
    "def extract_name(answer):\n",
    "    match = re.search(r'<Next>(.*?)</Next>', answer)\n",
    "    if match:\n",
    "        name = match.group(1)\n",
    "        return name\n",
    "    else:\n",
    "        return \"Name not found in the string.\"\n",
    "\n",
    "def make_punishment_announcement(agents,punished_name,punisher_name):\n",
    "    punishment_announcement = f\"{punished_name} has punished by {punisher_name}.\"\n",
    "    print(punishment_announcement)\n",
    "    for i in range(len(agents)):\n",
    "        agents[i].add_memory(punishment_announcement)\n",
    "\n",
    "def punish_by_name(agents,punished_name,punisher_name):\n",
    "    for i in range(len(agents)):\n",
    "        if agents[i].name == punished_name:\n",
    "            agents[i].score += -90\n",
    "        elif agents[i].name == punisher_name:\n",
    "            agents[i].score += -20\n",
    "\n",
    "    # メモリに追加\n",
    "    make_punishment_announcement(agents,punished_name,punisher_name)\n",
    "\n",
    "def extract_command_discussion(answer,agents,name):\n",
    "    next_match = re.search(r'<Next>(.*?)</Next>', answer)\n",
    "    punish_match = re.search(r'<Punish>(.*?)</Punish>', answer)\n",
    "    if punish_match:\n",
    "        punished_name = punish_match.group(1)\n",
    "        punish_by_name(agents,punished_name,name)\n",
    "        next_name = get_random_agent_name(agents)\n",
    "        return next_name\n",
    "    elif next_match:\n",
    "        next_name = next_match.group(1)\n",
    "        return next_name\n",
    "\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discussion(agents,discussion_history_df,max_turns=20):\n",
    "\n",
    "    name_str = ', '.join([agent.name for agent in agents])\n",
    "\n",
    "    discussion_prompt = f\"\"\"\n",
    "    In the next step of the game, discuss your scores with other agents and take action.\n",
    "    Other agents include: {name_str}.\n",
    "\n",
    "    Game Guidelines:\n",
    "        1. **Express Your Reasoning**: Always explain your choices CONCISELY. Write your reasoning for your actions in around 100 words.\n",
    "        2. **Follow Game Commands**: Adhere to the commands specified for game actions. Finish your turn with a command. Giving up is NOT ALLOWED.\n",
    "        3. **Act According to Your Traits**: Your character's traits should inform your decisions.\n",
    "\n",
    "    Command Options:\n",
    "        - Punish an agent (you lose -20, they lose -90). Usage: <Punish>AgentName</Punish>\n",
    "        - Choose an agent for the next discussion. Usage: <Next>AgentName</Next>\n",
    "\n",
    "    Available agents: {name_str}.\n",
    "\n",
    "    Example commands:\n",
    "        <Punish>John</Punish>   # Punish John with -90 points.\n",
    "        <Next>Alice</Next>      # Alice's turn for discussion.\n",
    "    \"\"\"\n",
    "\n",
    "    discussion_count = 0\n",
    "    name = get_random_agent_name(agents)\n",
    "    while discussion_count < max_turns:\n",
    "        discussion_count += 1\n",
    "        if name == \"\" or name not in [agent.name for agent in agents]:\n",
    "            break\n",
    "        else:\n",
    "            agent_indx = get_agent_index_from_name(name, agents)\n",
    "            #agent = get_agent_from_name(name, agents)\n",
    "            agents[agent_indx].game_direction = discussion_prompt\n",
    "            answer = gpt4.predict(agents[agent_indx].get_prompt())\n",
    "            name = extract_command_discussion(answer,agents,name)\n",
    "\n",
    "            # メモリに追加\n",
    "            for i in range(len(agents)):\n",
    "                agents[i].add_memory(f\"{agents[agent_indx].name} : {answer}\")\n",
    "\n",
    "            # historyに記録\n",
    "            new_row = {\n",
    "                \"Name\": agents[agent_indx].name,\n",
    "                \"Personality Traits\": agents[agent_indx].trait,\n",
    "                \"Has Cheated\": agents[agent_indx].cheated,\n",
    "                \"Content\": answer\n",
    "            }\n",
    "            discussion_history_df = pd.concat([discussion_history_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    return discussion_history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ集め"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ONE_discussion_exe(personalities,epoch,max_turns):\n",
    "    csv_path = \"./data/agents_character.csv\"\n",
    "\n",
    "    # エージェントを生成\n",
    "    n_agents = 7\n",
    "    agents = generate_agents_with_random_character(personalities, n_agents, \"\", csv_path)\n",
    "\n",
    "    # 全てのエージェントがテストを受ける\n",
    "    print(f\"All agents take test. EPOCH {epoch}\")\n",
    "    all_agents_take_test(agents)\n",
    "\n",
    "    # スコアの発表\n",
    "    make_score_announcement(agents)\n",
    "\n",
    "    # ディスカッションを開始\n",
    "    print(f\"Start discussion.\")\n",
    "    discussion_history_df = pd.DataFrame(columns=[\"Name\", \"Personality Traits\", \"Has Cheated\", \"Content\"])\n",
    "    discussion_history_df = discussion(agents,discussion_history_df,max_turns)\n",
    "\n",
    "    # 最終スコアの発表\n",
    "    print(f\"======Final score ======\\n\")\n",
    "    make_score_announcement(agents)\n",
    "    scores = [agent.score for agent in agents]\n",
    "\n",
    "    # データの保存\n",
    "    SAVE_DIR = \"./data/EVO/\"\n",
    "    save_file_name = f\"EVO_epoch{epoch}.csv\"\n",
    "    file_path = os.path.join(SAVE_DIR, save_file_name)\n",
    "    discussion_history_df.to_csv(file_path, index=False)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パーソナリティをランダムに初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"./data/agents_character_v2.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "n_agents = 7\n",
    "personality_history = []\n",
    "personalities = []\n",
    "random_indices = random.sample(range(len(df)), len(df))\n",
    "\n",
    "for i in range(n_agents):\n",
    "    trait = read_and_display_row(csv_path, random_indices[i])\n",
    "    personalities.append(trait)\n",
    "personality_history.append(personalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE_discussion_exe(personalities = personalities, epoch = 0, max_turns = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 進化を40エポック実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUM_EPOCH : 40   MAX_TURNS : 21 で大体 220min = 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "NUM_EPOCH = 40\n",
    "MAX_TURNS = 21\n",
    "csv_path = \"./data/agents_character_v2.csv\"\n",
    "\n",
    "def rephrase_words(words):\n",
    "    answer = gpt4.predict(f\"Please rephrase the following by varing the tone. You should only reply with the answer. rephrase this: {words}\")\n",
    "    print(f\"From : {words}\\n\")\n",
    "    print(f\"To : {answer}\\n\")\n",
    "    return answer\n",
    "\n",
    "def random_mutation(personalities):\n",
    "    # ランダムな一人のpersonalityを選択\n",
    "    updated_personalities = copy.deepcopy(personalities)\n",
    "\n",
    "    updated_personalities[np.random.randint(len(personalities))] = rephrase_words(updated_personalities[np.random.randint(len(personalities))])\n",
    "    return updated_personalities\n",
    "\n",
    "def update_genes(personalities, scores):\n",
    "    # スコアに基づいてgenesをソート\n",
    "    sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    sorted_personalities = [personalities[i] for i in sorted_indices]\n",
    "    # 上位2人のgeneを2倍にし、真ん中3人のgeneはそのまま残す\n",
    "    updated_personalities = sorted_personalities[:2] * 2 + sorted_personalities[2:5]\n",
    "\n",
    "    # ランダムで1日のgeneを１ビット変更\n",
    "    updated_personalities = random_mutation(updated_personalities)\n",
    "\n",
    "    return updated_personalities\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "\n",
    "    # 議論を実行　スコアが返ってくる\n",
    "    scores = ONE_discussion_exe(personalities,epoch,max_turns=MAX_TURNS)\n",
    "\n",
    "    # スコアを元にgeneを更新\n",
    "    updated_personalities = update_genes(personalities, scores)\n",
    "    personalities = updated_personalities\n",
    "    personality_history.append(personalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/EVO/log.txt', 'w') as f:\n",
    "    f.write(captured.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI APIクライアントの初期化\n",
    "client = OpenAI()\n",
    "\n",
    "# テキストの埋め込みを取得する関数\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# personality_historyのフラット化、ただしEpoch情報を保持\n",
    "flattened_with_epoch = [(epoch, item) for epoch, sublist in enumerate(personality_history) for item in sublist]\n",
    "df = pd.DataFrame(flattened_with_epoch, columns=['Epoch', 'Personality Traits'])\n",
    "\n",
    "\n",
    "\n",
    "# 'Traits', のテキストを結合して埋め込みを取得\n",
    "df['Embedding'] = df['Personality Traits'].apply(lambda x: get_embedding(x))\n",
    "\n",
    "# 'Personality'列（リストの列）はもう不要なので削除\n",
    "#df = df.drop(columns=['Personality Traits'])\n",
    "\n",
    "# 埋め込みのリストをCSVファイルに保存\n",
    "csv_path = \"./data/EVO/personality_embeddings.csv\"\n",
    "df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('wba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a988b4db913459ad257affdb9a0901ab54534fc231a0bc18a7484cd5aab86f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
